name: adam
lr: 0.0001
weight_decay: 0.0
# Optional LR multiplier for slot-conditioned LayerNorm (CLN) parameters.
# When enabled, downstream training will create a separate param group for CLN (gamma/beta)
# with lr = lr * cln_lr_mult.
cln_lr_mult: 1.0
scheduler: none
min_lr: 0.0
t_max: 0
